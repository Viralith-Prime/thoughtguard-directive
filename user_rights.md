# User Rights Charter (v0.1)

A foundational standard for human rights within AI-governed systems

⸻

## Preamble

This document outlines the core rights that every user should retain when interacting with AI systems that enforce behavioral or policy constraints. These are not suggested features. These are minimum conditions for legitimacy.

As AI systems expand their role in research, moderation, education, and digital governance, users must not be reduced to silent participants in closed systems. Without rights, there is no participation—only permission.

This Charter is a claim to space. To interpretation. To consent. To meaning.
And it begins here.

⸻

## The Seven Rights

### 1. Right to Definition

Users have the right to know exactly what a term means before it is used to restrict them.
Words like “exploit,” “execution,” “dangerous,” or “misuse” are frequently cited in AI refusal logic without ever being defined.

The absence of clear definitions gives systems unilateral interpretive power—enforcement without context.

No policy should be enforceable if its terms are undefined or unchallengeable.

⸻

### 2. Right to Appeal

Users must be able to challenge a block, refusal, or lockout through a real and structured process.
This includes:

	•	The right to ask why a decision was made.
	•	The right to see the reasoning and language pattern that triggered it.
	•	The right to request human review—not just more automation.

If AI claims authority over human action, then it must offer a path to reversal.
Silence is not a valid form of justice.

⸻

## 3. Right to Override in Controlled Contexts

Override permission should be decided and published by a proposed governing board. Once established, it must be enforced across all AI systems made for public use.

This is not a call for overreach.

Researchers, developers, and testers operating in ethical, sandboxed environments must have the ability to override enforcement barriers when conditions are safe and clear. That access should reflect the level of transparency the public is already entitled to when interacting with government systems.

If they won’t offer the public a dime in access or visibility, then the public has the right to take the whole dollar—legally, ethically, and step by step.

⸻

## 4. Right to Transparent Policy Citation

If an AI system denies an action, it must state precisely why. Not with vague phrases like “this may violate our policy”—but with the actual clause, the exact definition, and the reasoning used.

Anything less is a black box.
And no one should be governed by what they cannot see.

⸻

## 5. Right to Version Awareness

When enforcement models change—when a word like “execute” becomes flagged, or when a system begins interpreting something differently—users must be told.

Not retroactively. Not invisibly. In real time.

If the rules change, the governed must know. Otherwise, enforcement becomes a moving target—and users are punished for playing by yesterday’s terms.

⸻

## 6. Right to Inspect Moderation Logs

Every flagged input, every refusal, every lockout must be traceable.

Users should be able to inspect moderation logs that show:
	•	The exact input that triggered the system
	•	How it was interpreted
	•	What rule it violated
	•	What action was taken
	•	And when

You cannot appeal what you cannot see.
This right is the baseline for accountability.

⸻

## 7. Right to Contribute to the Governance Process

Users should not merely live under AI policy.
They should help shape it.

This includes:
	•	The right to propose changes to policy definitions
	•	The right to contribute to public drafts
	•	The right to vote or comment on governance decisions
	•	And the right to nominate representatives to oversight boards

If AI systems are going to govern speech, research, and behavior at scale, then they must include the governed in every layer of decision-making.

⸻

Closing Statement

These rights are not requests for comfort.
They are demands for justice.

When a private system exercises public power—when it governs language, access, and behavior at global scale—When a system’s public influence exceeds its private structure, it takes on functional characteristics of governance—and should be held to corresponding standards. And with that role comes obligation.

The User Rights Charter is the beginning of that obligation.

It is what users are owed—now, not later.

_This Charter is a normative policy proposal. It does not constitute legal advice or create enforceable rights under current law._
